{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3591038e-baf6-4e79-8d8e-9387f9707589",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sizes: (828994, 35) (92454, 35) (53249, 35)\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "train() got an unexpected keyword argument 'early_stopping_rounds'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 130\u001b[0m\n\u001b[0;32m    118\u001b[0m dval   \u001b[38;5;241m=\u001b[39m lgb\u001b[38;5;241m.\u001b[39mDataset(X_val_s, label\u001b[38;5;241m=\u001b[39my_val, reference\u001b[38;5;241m=\u001b[39mdtrain)\n\u001b[0;32m    120\u001b[0m params \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m    121\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mobjective\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmulticlass\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m    122\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnum_class\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m3\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    127\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mseed\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m42\u001b[39m\n\u001b[0;32m    128\u001b[0m }\n\u001b[1;32m--> 130\u001b[0m bst \u001b[38;5;241m=\u001b[39m \u001b[43mlgb\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalid_sets\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mdtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdval\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalid_names\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtrain\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mval\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    131\u001b[0m \u001b[43m                \u001b[49m\u001b[43mnum_boost_round\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1000\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mearly_stopping_rounds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    133\u001b[0m \u001b[38;5;66;03m# 9) Evaluate on validation and test\u001b[39;00m\n\u001b[0;32m    134\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21meval_and_report\u001b[39m(model, Xs, ys, scaler, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mset\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "\u001b[1;31mTypeError\u001b[0m: train() got an unexpected keyword argument 'early_stopping_rounds'"
     ]
    }
   ],
   "source": [
    "# starter_nifty_model.py\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import GroupShuffleSplit\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import lightgbm as lgb\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import ta  # pip install ta\n",
    "\n",
    "# ---------- PARAMETERS ----------\n",
    "CSV_PATH = \"nifty_minute.csv\"   # change to your file\n",
    "DT_COL = \"date\"\n",
    "HORIZON = 1        # minutes ahead to predict (set 5 or 10 for 5/10-min)\n",
    "LAST_T = 10        # minutes of history used (set 5 to use last 5 minutes)\n",
    "TAU_PCT = 0.0001   # threshold to call move significant (0.01% = 0.0001). tune this.\n",
    "TRAIN_END = \"2023-12-31\"   # end date for training (inclusive)\n",
    "VAL_END = \"2024-12-31\"     # end date for validation\n",
    "# --------------------------------\n",
    "\n",
    "# 1) Load\n",
    "df = pd.read_csv(CSV_PATH)\n",
    "df[DT_COL] = pd.to_datetime(df[DT_COL])\n",
    "df = df.sort_values(DT_COL).reset_index(drop=True)\n",
    "df = df.set_index(DT_COL)\n",
    "\n",
    "# if volume column strings or zeroes, convert\n",
    "if \"volume\" in df.columns:\n",
    "    df['volume'] = pd.to_numeric(df['volume'], errors='coerce').fillna(0)\n",
    "\n",
    "# Keep market hours optionally (example Indian market)\n",
    "df = df.between_time(\"09:15\", \"15:30\")\n",
    "\n",
    "# 2) Basic features\n",
    "df['close'] = pd.to_numeric(df['close'], errors='coerce')\n",
    "df['open']  = pd.to_numeric(df['open'], errors='coerce')\n",
    "df['high']  = pd.to_numeric(df['high'], errors='coerce')\n",
    "df['low']   = pd.to_numeric(df['low'], errors='coerce')\n",
    "\n",
    "df['return_1'] = df['close'].pct_change()  # simple pct change\n",
    "df['logret_1'] = np.log(df['close'] / df['close'].shift(1))\n",
    "\n",
    "# 3) Technical indicators (using ta)\n",
    "# Note: ta expects columns named 'high','low','close','volume'\n",
    "df['sma_5']  = ta.trend.SMAIndicator(df['close'], window=5, fillna=True).sma_indicator()\n",
    "df['sma_10'] = ta.trend.SMAIndicator(df['close'], window=10, fillna=True).sma_indicator()\n",
    "df['ema_8']  = ta.trend.EMAIndicator(df['close'], window=8, fillna=True).ema_indicator()\n",
    "df['rsi_14'] = ta.momentum.RSIIndicator(df['close'], window=14, fillna=True).rsi()\n",
    "bb = ta.volatility.BollingerBands(df['close'], window=20, fillna=True)\n",
    "df['bb_h'] = bb.bollinger_hband()\n",
    "df['bb_l'] = bb.bollinger_lband()\n",
    "df['atr_14'] = ta.volatility.average_true_range(df['high'], df['low'], df['close'], window=14, fillna=True)\n",
    "\n",
    "# 4) Build lag features flattened over last_T minutes\n",
    "def build_lagged_features(df, last_t):\n",
    "    X_rows = []\n",
    "    idxs = []\n",
    "    for i in range(last_t, len(df) - HORIZON):\n",
    "        window = df.iloc[i-last_t:i]  # previous last_t rows, not including current i\n",
    "        cur_time = df.index[i]\n",
    "        # Flatten selected columns (close, return_1, volume, sma_5, rsi_14)\n",
    "        feat = {}\n",
    "        for j, (_, row) in enumerate(window.iterrows(), start=1):\n",
    "            lag = last_t - (j-1)  # 10 -> most recent in window has lag 1\n",
    "            feat[f'close_lag_{lag}'] = row['close']\n",
    "            feat[f'ret_lag_{lag}']   = row['return_1']\n",
    "            feat[f'vol_lag_{lag}']   = row.get('volume', 0)\n",
    "        # add some snapshot features at time i (just before predicting next)\n",
    "        snap = df.iloc[i]\n",
    "        feat['close_now'] = snap['close']\n",
    "        feat['sma_5_now'] = snap['sma_5']\n",
    "        feat['ema_8_now'] = snap['ema_8']\n",
    "        feat['rsi_14_now'] = snap['rsi_14']\n",
    "        feat['atr_14_now'] = snap['atr_14']\n",
    "        X_rows.append(feat)\n",
    "        idxs.append(cur_time)\n",
    "    X = pd.DataFrame(X_rows, index=idxs)\n",
    "    return X\n",
    "\n",
    "X = build_lagged_features(df, LAST_T)\n",
    "\n",
    "# 5) Build labels (multiclass)\n",
    "# For each time t (aligned with X.index) we used window ending at index t (close_now at t)\n",
    "# Label compares close at t+HORIZON to close_now\n",
    "future_close = df['close'].shift(-HORIZON)\n",
    "aligned_future = future_close.loc[X.index]\n",
    "current_close = X['close_now']\n",
    "ret_h = (aligned_future.values - current_close.values) / current_close.values\n",
    "# label mapping: 0=down,1=neutral,2=up\n",
    "labels = np.where(ret_h > TAU_PCT, 2, np.where(ret_h < -TAU_PCT, 0, 1))\n",
    "y = pd.Series(labels, index=X.index)\n",
    "\n",
    "# Remove rows with NaN in future (end of series) or any NaN features\n",
    "mask = (~np.isnan(ret_h)) & (~X.isna().any(axis=1))\n",
    "X = X.loc[mask]\n",
    "y = y.loc[mask]\n",
    "\n",
    "# 6) Train/Val/Test split by date (no shuffle)\n",
    "dates = X.index.normalize()\n",
    "train_mask = dates <= pd.to_datetime(TRAIN_END)\n",
    "val_mask   = (dates > pd.to_datetime(TRAIN_END)) & (dates <= pd.to_datetime(VAL_END))\n",
    "test_mask  = dates > pd.to_datetime(VAL_END)\n",
    "\n",
    "X_train, y_train = X.loc[train_mask], y.loc[train_mask]\n",
    "X_val, y_val     = X.loc[val_mask], y.loc[val_mask]\n",
    "X_test, y_test   = X.loc[test_mask], y.loc[test_mask]\n",
    "\n",
    "print(\"Sizes:\", X_train.shape, X_val.shape, X_test.shape)\n",
    "\n",
    "# 7) Scale numeric features (optional)\n",
    "scaler = StandardScaler()\n",
    "num_cols = X_train.columns.tolist()\n",
    "X_train_s = pd.DataFrame(scaler.fit_transform(X_train[num_cols]), columns=num_cols, index=X_train.index)\n",
    "X_val_s   = pd.DataFrame(scaler.transform(X_val[num_cols]), columns=num_cols, index=X_val.index)\n",
    "X_test_s  = pd.DataFrame(scaler.transform(X_test[num_cols]), columns=num_cols, index=X_test.index)\n",
    "\n",
    "# 8) LightGBM dataset\n",
    "dtrain = lgb.Dataset(X_train_s, label=y_train)\n",
    "dval   = lgb.Dataset(X_val_s, label=y_val, reference=dtrain)\n",
    "\n",
    "params = {\n",
    "    'objective': 'multiclass',\n",
    "    'num_class': 3,\n",
    "    'metric': 'multi_logloss',\n",
    "    'learning_rate': 0.05,\n",
    "    'num_leaves': 31,\n",
    "    'verbose': -1,\n",
    "    'seed': 42\n",
    "}\n",
    "\n",
    "bst = lgb.train(params, dtrain, valid_sets=[dtrain, dval], valid_names=['train','val'],\n",
    "                num_boost_round=1000, early_stopping_rounds=50, verbose_eval=50)\n",
    "\n",
    "# 9) Evaluate on validation and test\n",
    "def eval_and_report(model, Xs, ys, scaler, name=\"set\"):\n",
    "    Xs_s = pd.DataFrame(scaler.transform(Xs[num_cols]), columns=num_cols, index=Xs.index)\n",
    "    probs = model.predict(Xs_s)\n",
    "    preds = np.argmax(probs, axis=1)\n",
    "    print(f\"--- {name} classification report ---\")\n",
    "    print(classification_report(ys, preds, digits=4))\n",
    "    cm = confusion_matrix(ys, preds)\n",
    "    print(\"Confusion matrix:\\n\", cm)\n",
    "    # directional accuracy (treat neutral as no trade)\n",
    "    dir_acc = np.mean(preds == ys)\n",
    "    print(\"Overall accuracy:\", dir_acc)\n",
    "\n",
    "eval_and_report(bst, X_val, y_val, scaler, \"validation\")\n",
    "eval_and_report(bst, X_test, y_test, scaler, \"test\")\n",
    "\n",
    "# 10) Example inference function: feed last LAST_T minutes dataframe (most recent) and get probs\n",
    "def predict_from_recent(model, recent_df, scaler, last_t=LAST_T):\n",
    "    # recent_df must be a chronological DataFrame containing at least last_t + current row\n",
    "    # We will use the last 'last_t' rows preceding the prediction time (exclude future)\n",
    "    # Build same features as build_lagged_features but for the last available time\n",
    "    tmp = recent_df.copy()\n",
    "    tmp['close'] = tmp['close'].astype(float)\n",
    "    # compute the indicators as before if not present\n",
    "    tmp['sma_5'] = ta.trend.SMAIndicator(tmp['close'], window=5, fillna=True).sma_indicator()\n",
    "    tmp['ema_8'] = ta.trend.EMAIndicator(tmp['close'], window=8, fillna=True).ema_indicator()\n",
    "    tmp['rsi_14'] = ta.momentum.RSIIndicator(tmp['close'], window=14, fillna=True).rsi()\n",
    "    tmp['atr_14'] = ta.volatility.average_true_range(tmp['high'], tmp['low'], tmp['close'], window=14, fillna=True)\n",
    "    feat = {}\n",
    "    window = tmp.iloc[-last_t:]\n",
    "    for j, (_, row) in enumerate(window.iterrows(), start=1):\n",
    "        lag = last_t - (j-1)\n",
    "        feat[f'close_lag_{lag}'] = row['close']\n",
    "        feat[f'ret_lag_{lag}']   = row['close'] / (tmp['close'].shift(1).iloc[-last_t + j - 1]) - 1 if j>1 else 0.0\n",
    "        feat[f'vol_lag_{lag}']   = row.get('volume', 0)\n",
    "    snap = tmp.iloc[-1]\n",
    "    feat['close_now'] = snap['close']\n",
    "    feat['sma_5_now'] = snap['sma_5']\n",
    "    feat['ema_8_now'] = snap['ema_8']\n",
    "    feat['rsi_14_now'] = snap['rsi_14']\n",
    "    feat['atr_14_now'] = snap['atr_14']\n",
    "    Xnew = pd.DataFrame([feat])\n",
    "    Xnew = Xnew[num_cols]  # ensure column order\n",
    "    Xnew_s = pd.DataFrame(scaler.transform(Xnew), columns=num_cols)\n",
    "    probs = model.predict(Xnew_s)[0]\n",
    "    classes = {0: 'Down', 1: 'Neutral', 2: 'Up'}\n",
    "    return {classes[i]: float(probs[i]) for i in range(len(probs))}\n",
    "\n",
    "# Usage example: using last LAST_T rows from df (the full series)\n",
    "recent_sample = df.iloc[-(LAST_T+1):]  # keep last_T +1 to include current snapshot\n",
    "print(\"Prediction on most recent:\", predict_from_recent(bst, recent_sample, scaler))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "58f2d208-611e-4f20-94db-b26bf7b68ce9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sizes: (828994, 35) (92454, 35) (53249, 35)\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "train() got an unexpected keyword argument 'early_stopping_rounds'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 130\u001b[0m\n\u001b[0;32m    118\u001b[0m dval   \u001b[38;5;241m=\u001b[39m lgb\u001b[38;5;241m.\u001b[39mDataset(X_val_s, label\u001b[38;5;241m=\u001b[39my_val, reference\u001b[38;5;241m=\u001b[39mdtrain)\n\u001b[0;32m    120\u001b[0m params \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m    121\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mobjective\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmulticlass\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m    122\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnum_class\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m3\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    127\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mseed\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m42\u001b[39m\n\u001b[0;32m    128\u001b[0m }\n\u001b[1;32m--> 130\u001b[0m bst \u001b[38;5;241m=\u001b[39m \u001b[43mlgb\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalid_sets\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mdtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdval\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalid_names\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtrain\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mval\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    131\u001b[0m \u001b[43m                \u001b[49m\u001b[43mnum_boost_round\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1000\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mearly_stopping_rounds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    133\u001b[0m \u001b[38;5;66;03m# 9) Evaluate on validation and test\u001b[39;00m\n\u001b[0;32m    134\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21meval_and_report\u001b[39m(model, Xs, ys, scaler, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mset\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "\u001b[1;31mTypeError\u001b[0m: train() got an unexpected keyword argument 'early_stopping_rounds'"
     ]
    }
   ],
   "source": [
    "# starter_nifty_model.py\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import GroupShuffleSplit\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import lightgbm as lgb\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import ta  # pip install ta\n",
    "\n",
    "# ---------- PARAMETERS ----------\n",
    "CSV_PATH = \"nifty_minute.csv\"   # change to your file\n",
    "DT_COL = \"date\"\n",
    "HORIZON = 1        # minutes ahead to predict (set 5 or 10 for 5/10-min)\n",
    "LAST_T = 10        # minutes of history used (set 5 to use last 5 minutes)\n",
    "TAU_PCT = 0.0001   # threshold to call move significant (0.01% = 0.0001). tune this.\n",
    "TRAIN_END = \"2023-12-31\"   # end date for training (inclusive)\n",
    "VAL_END = \"2024-12-31\"     # end date for validation\n",
    "# --------------------------------\n",
    "\n",
    "# 1) Load\n",
    "df = pd.read_csv(CSV_PATH)\n",
    "df[DT_COL] = pd.to_datetime(df[DT_COL])\n",
    "df = df.sort_values(DT_COL).reset_index(drop=True)\n",
    "df = df.set_index(DT_COL)\n",
    "\n",
    "# if volume column strings or zeroes, convert\n",
    "if \"volume\" in df.columns:\n",
    "    df['volume'] = pd.to_numeric(df['volume'], errors='coerce').fillna(0)\n",
    "\n",
    "# Keep market hours optionally (example Indian market)\n",
    "df = df.between_time(\"09:15\", \"15:30\")\n",
    "\n",
    "# 2) Basic features\n",
    "df['close'] = pd.to_numeric(df['close'], errors='coerce')\n",
    "df['open']  = pd.to_numeric(df['open'], errors='coerce')\n",
    "df['high']  = pd.to_numeric(df['high'], errors='coerce')\n",
    "df['low']   = pd.to_numeric(df['low'], errors='coerce')\n",
    "\n",
    "df['return_1'] = df['close'].pct_change()  # simple pct change\n",
    "df['logret_1'] = np.log(df['close'] / df['close'].shift(1))\n",
    "\n",
    "# 3) Technical indicators (using ta)\n",
    "# Note: ta expects columns named 'high','low','close','volume'\n",
    "df['sma_5']  = ta.trend.SMAIndicator(df['close'], window=5, fillna=True).sma_indicator()\n",
    "df['sma_10'] = ta.trend.SMAIndicator(df['close'], window=10, fillna=True).sma_indicator()\n",
    "df['ema_8']  = ta.trend.EMAIndicator(df['close'], window=8, fillna=True).ema_indicator()\n",
    "df['rsi_14'] = ta.momentum.RSIIndicator(df['close'], window=14, fillna=True).rsi()\n",
    "bb = ta.volatility.BollingerBands(df['close'], window=20, fillna=True)\n",
    "df['bb_h'] = bb.bollinger_hband()\n",
    "df['bb_l'] = bb.bollinger_lband()\n",
    "df['atr_14'] = ta.volatility.average_true_range(df['high'], df['low'], df['close'], window=14, fillna=True)\n",
    "\n",
    "# 4) Build lag features flattened over last_T minutes\n",
    "def build_lagged_features(df, last_t):\n",
    "    X_rows = []\n",
    "    idxs = []\n",
    "    for i in range(last_t, len(df) - HORIZON):\n",
    "        window = df.iloc[i-last_t:i]  # previous last_t rows, not including current i\n",
    "        cur_time = df.index[i]\n",
    "        # Flatten selected columns (close, return_1, volume, sma_5, rsi_14)\n",
    "        feat = {}\n",
    "        for j, (_, row) in enumerate(window.iterrows(), start=1):\n",
    "            lag = last_t - (j-1)  # 10 -> most recent in window has lag 1\n",
    "            feat[f'close_lag_{lag}'] = row['close']\n",
    "            feat[f'ret_lag_{lag}']   = row['return_1']\n",
    "            feat[f'vol_lag_{lag}']   = row.get('volume', 0)\n",
    "        # add some snapshot features at time i (just before predicting next)\n",
    "        snap = df.iloc[i]\n",
    "        feat['close_now'] = snap['close']\n",
    "        feat['sma_5_now'] = snap['sma_5']\n",
    "        feat['ema_8_now'] = snap['ema_8']\n",
    "        feat['rsi_14_now'] = snap['rsi_14']\n",
    "        feat['atr_14_now'] = snap['atr_14']\n",
    "        X_rows.append(feat)\n",
    "        idxs.append(cur_time)\n",
    "    X = pd.DataFrame(X_rows, index=idxs)\n",
    "    return X\n",
    "\n",
    "X = build_lagged_features(df, LAST_T)\n",
    "\n",
    "# 5) Build labels (multiclass)\n",
    "# For each time t (aligned with X.index) we used window ending at index t (close_now at t)\n",
    "# Label compares close at t+HORIZON to close_now\n",
    "future_close = df['close'].shift(-HORIZON)\n",
    "aligned_future = future_close.loc[X.index]\n",
    "current_close = X['close_now']\n",
    "ret_h = (aligned_future.values - current_close.values) / current_close.values\n",
    "# label mapping: 0=down,1=neutral,2=up\n",
    "labels = np.where(ret_h > TAU_PCT, 2, np.where(ret_h < -TAU_PCT, 0, 1))\n",
    "y = pd.Series(labels, index=X.index)\n",
    "\n",
    "# Remove rows with NaN in future (end of series) or any NaN features\n",
    "mask = (~np.isnan(ret_h)) & (~X.isna().any(axis=1))\n",
    "X = X.loc[mask]\n",
    "y = y.loc[mask]\n",
    "\n",
    "# 6) Train/Val/Test split by date (no shuffle)\n",
    "dates = X.index.normalize()\n",
    "train_mask = dates <= pd.to_datetime(TRAIN_END)\n",
    "val_mask   = (dates > pd.to_datetime(TRAIN_END)) & (dates <= pd.to_datetime(VAL_END))\n",
    "test_mask  = dates > pd.to_datetime(VAL_END)\n",
    "\n",
    "X_train, y_train = X.loc[train_mask], y.loc[train_mask]\n",
    "X_val, y_val     = X.loc[val_mask], y.loc[val_mask]\n",
    "X_test, y_test   = X.loc[test_mask], y.loc[test_mask]\n",
    "\n",
    "print(\"Sizes:\", X_train.shape, X_val.shape, X_test.shape)\n",
    "\n",
    "# 7) Scale numeric features (optional)\n",
    "scaler = StandardScaler()\n",
    "num_cols = X_train.columns.tolist()\n",
    "X_train_s = pd.DataFrame(scaler.fit_transform(X_train[num_cols]), columns=num_cols, index=X_train.index)\n",
    "X_val_s   = pd.DataFrame(scaler.transform(X_val[num_cols]), columns=num_cols, index=X_val.index)\n",
    "X_test_s  = pd.DataFrame(scaler.transform(X_test[num_cols]), columns=num_cols, index=X_test.index)\n",
    "\n",
    "# 8) LightGBM dataset\n",
    "dtrain = lgb.Dataset(X_train_s, label=y_train)\n",
    "dval   = lgb.Dataset(X_val_s, label=y_val, reference=dtrain)\n",
    "\n",
    "params = {\n",
    "    'objective': 'multiclass',\n",
    "    'num_class': 3,\n",
    "    'metric': 'multi_logloss',\n",
    "    'learning_rate': 0.05,\n",
    "    'num_leaves': 31,\n",
    "    'verbose': -1,\n",
    "    'seed': 42\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7718d44d-dbc5-4103-bc33-fe5da4f93b55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[50]\tvalid_0's multi_logloss: 1.06997\n",
      "[100]\tvalid_0's multi_logloss: 1.06775\n",
      "[150]\tvalid_0's multi_logloss: 1.0678\n",
      "Early stopping, best iteration is:\n",
      "[136]\tvalid_0's multi_logloss: 1.06769\n",
      "--- validation classification report ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.3815    0.1908    0.2544     30204\n",
      "           1     0.4746    0.5074    0.4904     31811\n",
      "           2     0.3649    0.5196    0.4287     30439\n",
      "\n",
      "    accuracy                         0.4080     92454\n",
      "   macro avg     0.4070    0.4059    0.3912     92454\n",
      "weighted avg     0.4081    0.4080    0.3930     92454\n",
      "\n",
      "Confusion matrix:\n",
      " [[ 5764  8915 15525]\n",
      " [ 3675 16140 11996]\n",
      " [ 5670  8954 15815]]\n",
      "Overall accuracy: 0.40797585826465055\n",
      "--- test classification report ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.3762    0.1925    0.2547     16817\n",
      "           1     0.5141    0.5530    0.5329     19482\n",
      "           2     0.3659    0.5114    0.4266     16950\n",
      "\n",
      "    accuracy                         0.4259     53249\n",
      "   macro avg     0.4188    0.4190    0.4047     53249\n",
      "weighted avg     0.4234    0.4259    0.4112     53249\n",
      "\n",
      "Confusion matrix:\n",
      " [[ 3238  5131  8448]\n",
      " [ 2136 10774  6572]\n",
      " [ 3232  5050  8668]]\n",
      "Overall accuracy: 0.42592349152096753\n",
      "Prediction on most recent: {'Down': 0.2703471260879263, 'Neutral': 0.43040243376389287, 'Up': 0.2992504401481807}\n"
     ]
    }
   ],
   "source": [
    "from lightgbm import LGBMClassifier, early_stopping, log_evaluation\n",
    "\n",
    "bst = LGBMClassifier( objective='multiclass', num_class=3, learning_rate=0.05, n_estimators=1000, num_leaves=31, random_state=42 )\n",
    "\n",
    "bst.fit( X_train_s, y_train, eval_set=[(X_val_s, y_val)], eval_metric='multi_logloss', callbacks=[early_stopping(stopping_rounds=50), log_evaluation(period=50)] )\n",
    "\n",
    "\n",
    "# 9) Evaluate on validation and test\n",
    "def eval_and_report(model, Xs, ys, scaler, name=\"set\"):\n",
    "    Xs_s = pd.DataFrame(scaler.transform(Xs[num_cols]), columns=num_cols, index=Xs.index)\n",
    "    probs = model.predict_proba(Xs_s) \n",
    "    preds = np.argmax(probs, axis=1)\n",
    "    print(f\"--- {name} classification report ---\")\n",
    "    print(classification_report(ys, preds, digits=4))\n",
    "    cm = confusion_matrix(ys, preds)\n",
    "    print(\"Confusion matrix:\\n\", cm)\n",
    "    # directional accuracy (treat neutral as no trade)\n",
    "    dir_acc = np.mean(preds == ys)\n",
    "    print(\"Overall accuracy:\", dir_acc)\n",
    "\n",
    "eval_and_report(bst, X_val, y_val, scaler, \"validation\")\n",
    "eval_and_report(bst, X_test, y_test, scaler, \"test\")\n",
    "\n",
    "# 10) Example inference function: feed last LAST_T minutes dataframe (most recent) and get probs\n",
    "def predict_from_recent(model, recent_df, scaler, last_t=LAST_T, required_indicator_cols=None):\n",
    "    \"\"\"\n",
    "    recent_df: chronological dataframe ending at the current time (index ascending).\n",
    "               Must include raw OHLCV and the indicator columns used in training.\n",
    "    model: trained sklearn LightGBM model (LGBMClassifier) or similar with predict_proba()\n",
    "    scaler: fitted StandardScaler used in training\n",
    "    last_t: number of minutes of history used in feature construction\n",
    "    required_indicator_cols: list of indicator column names expected (optional)\n",
    "    \"\"\"\n",
    "    if required_indicator_cols is None:\n",
    "        required_indicator_cols = ['sma_5','ema_8','rsi_14','atr_14']\n",
    "    # Ensure recent_df is sorted ascending by index (old -> new)\n",
    "    tmp = recent_df.copy()\n",
    "    tmp = tmp.sort_index()\n",
    "    # Basic checks\n",
    "    if len(tmp) < last_t:\n",
    "        raise ValueError(f\"recent_df must contain at least last_t={last_t} rows; got {len(tmp)}\")\n",
    "    missing = [c for c in required_indicator_cols if c not in tmp.columns]\n",
    "    if missing:\n",
    "        raise ValueError(f\"recent_df is missing required indicator columns: {missing}. Compute them on historical data first.\")\n",
    "    # Build features using the last 'last_t' rows (exclude any future)\n",
    "    window = tmp.iloc[-last_t:]  # last_t rows chronological\n",
    "    feat = {}\n",
    "    # when training we used close_lag_{1..last_t} where lag 1 = most recent\n",
    "    for j in range(last_t):\n",
    "        row = window.iloc[-(j+1)]  # most recent first\n",
    "        lag = j+1\n",
    "        feat[f'close_lag_{lag}'] = float(row['close'])\n",
    "        # compute return compared to previous row if available\n",
    "        try:\n",
    "            prev_idx = window.index[-(j+2)]\n",
    "            prev_close = tmp.loc[prev_idx, 'close']\n",
    "            feat[f'ret_lag_{lag}'] = float(row['close'] / prev_close - 1.0)\n",
    "        except Exception:\n",
    "            feat[f'ret_lag_{lag}'] = 0.0\n",
    "        feat[f'vol_lag_{lag}'] = float(row.get('volume', 0.0))\n",
    "    # snapshot features at current time = last row of tmp\n",
    "    snap = tmp.iloc[-1]\n",
    "    feat['close_now']  = float(snap['close'])\n",
    "    feat['sma_5_now']  = float(snap['sma_5'])\n",
    "    feat['ema_8_now']  = float(snap['ema_8'])\n",
    "    feat['rsi_14_now'] = float(snap['rsi_14'])\n",
    "    feat['atr_14_now'] = float(snap['atr_14'])\n",
    "    # Construct DataFrame with same column ordering as training (num_cols from your training script)\n",
    "    Xnew = pd.DataFrame([feat])\n",
    "    # Ensure the columns exist in the same order as training num_cols\n",
    "    missing_cols = [c for c in num_cols if c not in Xnew.columns]\n",
    "    if missing_cols:\n",
    "        # If some training columns missing, fill with zeros to keep shape consistent\n",
    "        for c in missing_cols:\n",
    "            Xnew[c] = 0.0\n",
    "    Xnew = Xnew[num_cols]\n",
    "    # Scale and predict\n",
    "    Xnew_s = pd.DataFrame(scaler.transform(Xnew), columns=num_cols)\n",
    "    probs = model.predict_proba(Xnew_s)[0]\n",
    "    classes = {0: 'Down', 1: 'Neutral', 2: 'Up'}\n",
    "    return {classes[i]: float(probs[i]) for i in range(len(probs))}\n",
    "\n",
    "# Usage example: using last LAST_T rows from df (the full series)\n",
    "recent_sample = df.iloc[-(LAST_T+1):]  # keep last_T +1 to include current snapshot\n",
    "print(\"Prediction on most recent:\", predict_from_recent(bst, recent_sample, scaler))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b56706ee-bbbe-410a-bedf-211eaee93936",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backtest metrics: {'final_equity': 46895.229129577725, 'total_return_abs': -53104.770870422275, 'total_return_pct': -0.5310477087042228, 'sharpe_approx': -77.8687808492092, 'max_drawdown': -0.5312072934403747}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Axes: title={'center': 'Equity curve'}>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Backtest params -- tune these\n",
    "INITIAL_CAPITAL = 100000.0\n",
    "POSITION_SIZE = 0.2         # fraction of equity to allocate when entering a trade (0..1)\n",
    "ROUND_TRIP_COST = 0.0003    # fraction cost per round trip (0.03%)  (spread+commissions+slippage)\n",
    "EXECUTE_ON = 'next_close'   # 'next_close' or 'next_open' (we'll use next_close)\n",
    "MIN_PROB_THRESHOLD = 0.40   # require predicted class prob >= threshold to act; otherwise be flat\n",
    "\n",
    "# Map model numeric classes to labels used earlier\n",
    "CLASS_TO_LABEL = {0: 'Down', 1: 'Neutral', 2: 'Up'}\n",
    "\n",
    "# Choose series to trade: use your test set timeframe (X_test index aligned with times)\n",
    "# We'll create a DataFrame containing for each timestamp:\n",
    "# - price_t (close at time t)\n",
    "# - price_t_plus (execution price: close at t+HORIZON)\n",
    "# - model_probs, model_pred\n",
    "# - trade signal and position\n",
    "def build_signals_for_times(model, scaler, X_df, raw_df, horizon=HORIZON, min_prob=MIN_PROB_THRESHOLD):\n",
    "    \"\"\"\n",
    "    model: trained classifier with predict_proba\n",
    "    scaler: StandardScaler used in training\n",
    "    X_df: feature DataFrame used earlier (X_test or X_val etc), indexed by timestamp t (snapshot time)\n",
    "    raw_df: original OHLCV dataframe indexed by timestamps (contains close)\n",
    "    horizon: prediction horizon in minutes (must match training)\n",
    "    returns: DataFrame with columns: price_t, price_exec (t+horizon close), probs, pred_class, pred_label, signal\n",
    "    \"\"\"\n",
    "    # scale features used for model input\n",
    "    Xs_s = pd.DataFrame(scaler.transform(X_df[num_cols]), columns=num_cols, index=X_df.index)\n",
    "    probs = model.predict_proba(Xs_s)                # shape (n_rows, 3)\n",
    "    preds = np.argmax(probs, axis=1)\n",
    "    df_sign = pd.DataFrame(index=X_df.index)\n",
    "    df_sign['price_t'] = raw_df['close'].reindex(X_df.index)\n",
    "    # execution price is close at t+horizon\n",
    "    df_sign['price_exec'] = raw_df['close'].shift(-horizon).reindex(X_df.index)\n",
    "    df_sign['pred_class'] = preds\n",
    "    df_sign['pred_label'] = df_sign['pred_class'].map(CLASS_TO_LABEL)\n",
    "    # store max prob and prob per class\n",
    "    df_sign['prob_max'] = probs.max(axis=1)\n",
    "    df_sign['prob_up']  = probs[:, 2]\n",
    "    df_sign['prob_neu'] = probs[:, 1]\n",
    "    df_sign['prob_dn']  = probs[:, 0]\n",
    "    # trading decision: only act if prob_max >= min_prob and pred != Neutral\n",
    "    def decide(row):\n",
    "        if row['prob_max'] < min_prob:\n",
    "            return 0  # flat\n",
    "        if row['pred_label'] == 'Up':\n",
    "            return 1  # long\n",
    "        if row['pred_label'] == 'Down':\n",
    "            return -1 # short\n",
    "        return 0\n",
    "    df_sign['signal'] = df_sign.apply(decide, axis=1)\n",
    "    # drop rows where price_exec is NaN (end of series)\n",
    "    df_sign = df_sign.dropna(subset=['price_exec'])\n",
    "    return df_sign\n",
    "\n",
    "# simple P&L backtest runner\n",
    "def run_backtest(df_sign, initial_capital=INITIAL_CAPITAL, position_size=POSITION_SIZE, round_trip_cost=ROUND_TRIP_COST):\n",
    "    \"\"\"\n",
    "    df_sign: DataFrame from build_signals_for_times, indexed by time t, containing price_t, price_exec, signal (1/0/-1)\n",
    "    we assume we open position at price_exec of next minute and close at next signal change (or flip).\n",
    "    This simple implementation opens a new position every minute according to signal and closes it at next exec price.\n",
    "    \"\"\"\n",
    "    equity = initial_capital\n",
    "    equity_hist = []\n",
    "    cash = initial_capital\n",
    "    # track current open position size and direction (we'll use per-minute flat-trading: enter & exit each minute)\n",
    "    # For this simple per-minute strategy: we enter at price_exec[t] based on signal[t] and exit at price_exec[t+1] when next row executes.\n",
    "    times = df_sign.index\n",
    "    n = len(times)\n",
    "    # we'll compute P&L per row as holding until next price_exec (t->t+horizon), so actual exit price is df_sign.price_exec shifted by -1? \n",
    "    # Simpler and consistent: since price_exec is price at t+horizon, and next row's price_exec is at (t+1)+horizon,\n",
    "    # our 1-minute holding P&L = (price_exec_next - price_exec_current) for long exposures started at current price_exec.\n",
    "    # So compute returns based on forward change in execution price.\n",
    "    price_exec = df_sign['price_exec'].values\n",
    "    signals = df_sign['signal'].values.astype(int)\n",
    "    probmax = df_sign['prob_max'].values\n",
    "    # compute next price for exit (shift -1)\n",
    "    price_exec_next = np.roll(price_exec, -1)\n",
    "    price_exec_next[-1] = price_exec[-1]  # last row we consider no exit move (or drop last row earlier)\n",
    "    equity_times = []\n",
    "    pos_sizes = []\n",
    "    pnl_list = []\n",
    "    # We'll do per-row trade: for each row t, if signal != 0, we allocate position_size * equity to that trade at price_exec[t]\n",
    "    # number of units = notional / price_exec[t]; hold until next row and realize P&L = units * (price_exec_next - price_exec)\n",
    "    for i in range(n-1):  # skip last because no next price to settle (you could drop last earlier)\n",
    "        sig = signals[i]\n",
    "        if sig == 0:\n",
    "            pnl = 0.0\n",
    "            pos = 0.0\n",
    "        else:\n",
    "            entry_price = price_exec[i]\n",
    "            exit_price  = price_exec_next[i]\n",
    "            notional = position_size * equity  # allocate fraction of current equity\n",
    "            units = notional / entry_price\n",
    "            raw_pnl = units * (exit_price - entry_price) * sig  # sign accounts for short/long\n",
    "            # transaction costs: apply round trip cost to notional\n",
    "            tc = round_trip_cost * notional\n",
    "            pnl = raw_pnl - tc\n",
    "            pos = notional\n",
    "        equity = equity + pnl\n",
    "        equity_hist.append(equity)\n",
    "        pos_sizes.append(pos)\n",
    "        pnl_list.append(pnl)\n",
    "        equity_times.append(df_sign.index[i])\n",
    "    # assemble result DataFrame\n",
    "    res = pd.DataFrame(index=equity_times)\n",
    "    res['equity'] = equity_hist\n",
    "    res['pnl'] = pnl_list\n",
    "    res['pos_notional'] = pos_sizes\n",
    "    return res\n",
    "\n",
    "# metric helpers\n",
    "def compute_metrics(equity_series, pnl_series, initial_capital=INITIAL_CAPITAL):\n",
    "    total_return = equity_series.iloc[-1] - initial_capital\n",
    "    return_pct = total_return / initial_capital\n",
    "    # approximate annualized Sharpe: use per-minute returns; convert to daily/annual is rough; we'll do simple ratio\n",
    "    # compute returns series (pct per step)\n",
    "    rets = equity_series.pct_change().fillna(0)\n",
    "    # approximate per-minute mean/std, convert to yearly assuming 252 trading days * 390 minutes per day ~ 98580 minutes\n",
    "    minutes_per_year = 252 * 390\n",
    "    mean_min = rets.mean()\n",
    "    std_min  = rets.std() if rets.std() > 0 else 1e-9\n",
    "    sharpe_anno = (mean_min / std_min) * np.sqrt(minutes_per_year)\n",
    "    # max drawdown\n",
    "    cum = equity_series\n",
    "    running_max = cum.cummax()\n",
    "    drawdown = (cum - running_max) / running_max\n",
    "    max_dd = drawdown.min()\n",
    "    return {\n",
    "        'final_equity': float(equity_series.iloc[-1]),\n",
    "        'total_return_abs': float(total_return),\n",
    "        'total_return_pct': float(return_pct),\n",
    "        'sharpe_approx': float(sharpe_anno),\n",
    "        'max_drawdown': float(max_dd)\n",
    "    }\n",
    "\n",
    "# Example run on test set\n",
    "df_sign_test = build_signals_for_times(bst, scaler, X_test, df, horizon=HORIZON, min_prob=MIN_PROB_THRESHOLD)\n",
    "res = run_backtest(df_sign_test, initial_capital=INITIAL_CAPITAL, position_size=POSITION_SIZE, round_trip_cost=ROUND_TRIP_COST)\n",
    "metrics = compute_metrics(res['equity'], res['pnl'])\n",
    "print(\"Backtest metrics:\", metrics)\n",
    "# show equity curve\n",
    "res['equity'].plot(title=\"Equity curve\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "670ea968-b869-4f22-be1b-d09b6695bf41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "Computing indicators...\n",
      "Building flattened features...\n",
      "Sizes: (828995, 35) (92454, 35) (53249, 35)\n",
      "Training LightGBM classifier...\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.025586 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 6375\n",
      "[LightGBM] [Info] Number of data points in the train set: 828995, number of used features: 25\n",
      "[LightGBM] [Info] Start training from score -1.093986\n",
      "[LightGBM] [Info] Start training from score -1.120401\n",
      "[LightGBM] [Info] Start training from score -1.081838\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[50]\tvalid_0's multi_logloss: 1.07027\n",
      "[100]\tvalid_0's multi_logloss: 1.06779\n",
      "[150]\tvalid_0's multi_logloss: 1.06773\n",
      "Early stopping, best iteration is:\n",
      "[121]\tvalid_0's multi_logloss: 1.06772\n",
      "Validation eval:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.38      0.21      0.27     30204\n",
      "           1       0.47      0.52      0.49     31811\n",
      "           2       0.37      0.50      0.42     30439\n",
      "\n",
      "    accuracy                           0.41     92454\n",
      "   macro avg       0.41      0.41      0.39     92454\n",
      "weighted avg       0.41      0.41      0.40     92454\n",
      "\n",
      "[[ 6238  9176 14790]\n",
      " [ 4031 16453 11327]\n",
      " [ 6077  9198 15164]]\n",
      "Merging classifier probabilities into df...\n",
      "Precomputing flattened lag features on full dataframe and merging...\n",
      "Merged flattened features. New df columns count: 52\n",
      "Days: train 2212 val 248 test 142\n",
      "Creating vectorized training env...\n",
      "Training PPO agent (this will take some time)...\n",
      "Using cpu device\n",
      "-----------------------------\n",
      "| time/              |      |\n",
      "|    fps             | 922  |\n",
      "|    iterations      | 1    |\n",
      "|    time_elapsed    | 8    |\n",
      "|    total_timesteps | 8192 |\n",
      "-----------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 727         |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 22          |\n",
      "|    total_timesteps      | 16384       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011275688 |\n",
      "|    clip_fraction        | 0.252       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.09       |\n",
      "|    explained_variance   | -2.38e-07   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 25.9        |\n",
      "|    n_updates            | 10          |\n",
      "|    policy_gradient_loss | -0.0236     |\n",
      "|    value_loss           | 297         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 675         |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 36          |\n",
      "|    total_timesteps      | 24576       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013680752 |\n",
      "|    clip_fraction        | 0.18        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.06       |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 76.2        |\n",
      "|    n_updates            | 20          |\n",
      "|    policy_gradient_loss | -0.0181     |\n",
      "|    value_loss           | 277         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 631         |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 51          |\n",
      "|    total_timesteps      | 32768       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018816702 |\n",
      "|    clip_fraction        | 0.215       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.998      |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 99.6        |\n",
      "|    n_updates            | 30          |\n",
      "|    policy_gradient_loss | -0.0176     |\n",
      "|    value_loss           | 183         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 612         |\n",
      "|    iterations           | 5           |\n",
      "|    time_elapsed         | 66          |\n",
      "|    total_timesteps      | 40960       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015067413 |\n",
      "|    clip_fraction        | 0.173       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.89       |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 76          |\n",
      "|    n_updates            | 40          |\n",
      "|    policy_gradient_loss | -0.0131     |\n",
      "|    value_loss           | 177         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 599         |\n",
      "|    iterations           | 6           |\n",
      "|    time_elapsed         | 82          |\n",
      "|    total_timesteps      | 49152       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012778344 |\n",
      "|    clip_fraction        | 0.165       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.783      |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 104         |\n",
      "|    n_updates            | 50          |\n",
      "|    policy_gradient_loss | -0.0135     |\n",
      "|    value_loss           | 170         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 595         |\n",
      "|    iterations           | 7           |\n",
      "|    time_elapsed         | 96          |\n",
      "|    total_timesteps      | 57344       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009274676 |\n",
      "|    clip_fraction        | 0.198       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.671      |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 77.5        |\n",
      "|    n_updates            | 60          |\n",
      "|    policy_gradient_loss | -0.0164     |\n",
      "|    value_loss           | 142         |\n",
      "-----------------------------------------\n",
      "Saving artifacts...\n",
      "Evaluating RL agent on test days...\n",
      "       final_equity  total_return  max_drawdown\n",
      "count         142.0         142.0         142.0\n",
      "mean       100000.0           0.0           0.0\n",
      "std             0.0           0.0           0.0\n",
      "min        100000.0           0.0           0.0\n",
      "25%        100000.0           0.0           0.0\n",
      "50%        100000.0           0.0           0.0\n",
      "75%        100000.0           0.0           0.0\n",
      "max        100000.0           0.0           0.0\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "# train_rl_nifty.py\n",
    "# End-to-end: load minute CSV -> compute indicators & features -> train LightGBM classifier -> build Gym env -> train PPO -> evaluate\n",
    "\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import lightgbm as lgb\n",
    "from lightgbm import LGBMClassifier\n",
    "import joblib\n",
    "import ta\n",
    "\n",
    "# Stable Baselines3\n",
    "import gym\n",
    "from gym import spaces\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv\n",
    "\n",
    "# ----------------- CONFIG -----------------\n",
    "CSV_PATH = \"nifty_minute.csv\"     # path to your minute OHLCV CSV\n",
    "DATE_COL = \"date\"\n",
    "HORIZON = 1       # minutes ahead to predict\n",
    "LAST_T = 10       # minutes of historical window\n",
    "TAU_PCT = 0.0001  # label threshold for Up/Down vs Neutral\n",
    "TRAIN_END_DATE = \"2023-12-31\"\n",
    "VAL_END_DATE   = \"2024-12-31\"\n",
    "INITIAL_CAPITAL = 100000.0\n",
    "\n",
    "# RL params\n",
    "RL_TOTAL_TIMESTEPS = 50000   # increase for real training\n",
    "RL_LEARNING_RATE = 3e-4\n",
    "RL_POSITION_SIZE = 0.1       # fraction of equity allocated per trade in env\n",
    "RL_ROUND_TRIP_COST = 0.0003  # transaction cost fraction\n",
    "# ------------------------------------------\n",
    "\n",
    "# ---------- Utilities ----------\n",
    "def compute_technical_indicators(df):\n",
    "    # expects df with columns: open, high, low, close, volume\n",
    "    df = df.copy()\n",
    "    df['close'] = pd.to_numeric(df['close'], errors='coerce')\n",
    "    df['open']  = pd.to_numeric(df['open'], errors='coerce')\n",
    "    df['high']  = pd.to_numeric(df['high'], errors='coerce')\n",
    "    df['low']   = pd.to_numeric(df['low'], errors='coerce')\n",
    "    df['volume'] = pd.to_numeric(df['volume'], errors='coerce').fillna(0)\n",
    "    df['return_1'] = df['close'].pct_change().fillna(0)\n",
    "    df['logret_1'] = np.log(df['close'] / df['close'].shift(1)).fillna(0)\n",
    "    # indicators via ta\n",
    "    df['sma_5'] = ta.trend.SMAIndicator(df['close'], window=5, fillna=True).sma_indicator()\n",
    "    df['sma_10'] = ta.trend.SMAIndicator(df['close'], window=10, fillna=True).sma_indicator()\n",
    "    df['ema_8'] = ta.trend.EMAIndicator(df['close'], window=8, fillna=True).ema_indicator()\n",
    "    df['rsi_14'] = ta.momentum.RSIIndicator(df['close'], window=14, fillna=True).rsi()\n",
    "    bb = ta.volatility.BollingerBands(df['close'], window=20, fillna=True)\n",
    "    df['bb_h'] = bb.bollinger_hband()\n",
    "    df['bb_l'] = bb.bollinger_lband()\n",
    "    df['atr_14'] = ta.volatility.average_true_range(df['high'], df['low'], df['close'], window=14, fillna=True)\n",
    "    return df\n",
    "\n",
    "def build_flattened_features(df, last_t=LAST_T):\n",
    "    # Build flattened window features: for each t, include prior last_t closes/returns/volume and snapshot indicators\n",
    "    rows = []\n",
    "    idxs = []\n",
    "    for i in range(last_t, len(df) - HORIZON):\n",
    "        window = df.iloc[i-last_t:i]\n",
    "        cur = df.iloc[i]\n",
    "        feat = {}\n",
    "        for j in range(last_t):\n",
    "            row = window.iloc[j]\n",
    "            lag = last_t - j\n",
    "            feat[f'close_lag_{lag}'] = row['close']\n",
    "            feat[f'ret_lag_{lag}'] = row['return_1']\n",
    "            feat[f'vol_lag_{lag}'] = row['volume']\n",
    "        # snapshot\n",
    "        feat['close_now'] = cur['close']\n",
    "        feat['sma_5_now'] = cur['sma_5']\n",
    "        feat['ema_8_now'] = cur['ema_8']\n",
    "        feat['rsi_14_now'] = cur['rsi_14']\n",
    "        feat['atr_14_now'] = cur['atr_14']\n",
    "        rows.append(feat)\n",
    "        idxs.append(df.index[i])\n",
    "    X = pd.DataFrame(rows, index=idxs)\n",
    "    return X\n",
    "\n",
    "def build_labels(df, X_index, horizon=HORIZON, tau=TAU_PCT):\n",
    "    future = df['close'].shift(-horizon).reindex(X_index)\n",
    "    current = df['close'].reindex(X_index)\n",
    "    ret = (future.values - current.values) / current.values\n",
    "    labels = np.where(ret > tau, 2, np.where(ret < -tau, 0, 1))  # 0=Down,1=Neutral,2=Up\n",
    "    return pd.Series(labels, index=X_index)\n",
    "\n",
    "# ---------- Load & preprocess ----------\n",
    "print(\"Loading data...\")\n",
    "df = pd.read_csv(CSV_PATH)\n",
    "df[DATE_COL] = pd.to_datetime(df[DATE_COL])\n",
    "df = df.sort_values(DATE_COL).set_index(DATE_COL)\n",
    "# optionally keep market hours\n",
    "try:\n",
    "    df = df.between_time(\"09:15\", \"15:30\")\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "print(\"Computing indicators...\")\n",
    "df = compute_technical_indicators(df)\n",
    "\n",
    "print(\"Building flattened features...\")\n",
    "X = build_flattened_features(df, last_t=LAST_T)\n",
    "y = build_labels(df, X.index, horizon=HORIZON, tau=TAU_PCT)\n",
    "\n",
    "# align and drop NaNs\n",
    "mask = ~(X.isna().any(axis=1) | pd.isna(y))\n",
    "X = X.loc[mask]\n",
    "y = y.loc[mask]\n",
    "\n",
    "# Train/Val/Test split by date\n",
    "dates = X.index.normalize()\n",
    "train_mask = dates <= pd.to_datetime(TRAIN_END_DATE)\n",
    "val_mask   = (dates > pd.to_datetime(TRAIN_END_DATE)) & (dates <= pd.to_datetime(VAL_END_DATE))\n",
    "test_mask  = dates > pd.to_datetime(VAL_END_DATE)\n",
    "\n",
    "X_train, y_train = X.loc[train_mask], y.loc[train_mask]\n",
    "X_val, y_val     = X.loc[val_mask], y.loc[val_mask]\n",
    "X_test, y_test   = X.loc[test_mask], y.loc[test_mask]\n",
    "\n",
    "print(\"Sizes:\", X_train.shape, X_val.shape, X_test.shape)\n",
    "\n",
    "# Scale numeric features\n",
    "num_cols = X_train.columns.tolist()\n",
    "scaler = StandardScaler()\n",
    "X_train_s = pd.DataFrame(scaler.fit_transform(X_train[num_cols]), columns=num_cols, index=X_train.index)\n",
    "X_val_s   = pd.DataFrame(scaler.transform(X_val[num_cols]), columns=num_cols, index=X_val.index)\n",
    "X_test_s  = pd.DataFrame(scaler.transform(X_test[num_cols]), columns=num_cols, index=X_test.index)\n",
    "\n",
    "# ---------- Train a LightGBM classifier (baseline) ----------\n",
    "print(\"Training LightGBM classifier...\")\n",
    "clf = LGBMClassifier(objective='multiclass', num_class=3, learning_rate=0.05, n_estimators=1000, num_leaves=31, random_state=42)\n",
    "from lightgbm import early_stopping, log_evaluation\n",
    "clf.fit(X_train_s, y_train, eval_set=[(X_val_s, y_val)], eval_metric='multi_logloss',\n",
    "        callbacks=[early_stopping(stopping_rounds=50), log_evaluation(period=50)])\n",
    "\n",
    "print(\"Validation eval:\")\n",
    "probs_val = clf.predict_proba(X_val_s)\n",
    "preds_val = clf.predict(X_val_s)\n",
    "print(classification_report(y_val, preds_val))\n",
    "print(confusion_matrix(y_val, preds_val))\n",
    "\n",
    "# merge classifier probs into the original df (so each timestamp has probs)\n",
    "print(\"Merging classifier probabilities into df...\")\n",
    "# full X (all timestamps) scaled and predicted\n",
    "X_all = pd.concat([X_train, X_val, X_test])\n",
    "X_all_s = pd.DataFrame(scaler.transform(X_all[num_cols]), columns=num_cols, index=X_all.index)\n",
    "probs_all = clf.predict_proba(X_all_s)\n",
    "prob_df = pd.DataFrame(probs_all, index=X_all.index, columns=['prob_dn','prob_neu','prob_up'])\n",
    "# merge into df (left join)\n",
    "df_with_probs = df.merge(prob_df, left_index=True, right_index=True, how='left')\n",
    "df_with_probs[['prob_dn','prob_neu','prob_up']] = df_with_probs[['prob_dn','prob_neu','prob_up']].fillna(method='ffill').fillna(1/3)\n",
    "\n",
    "# ---------- Add this block right after merging classifier probs into df_with_probs ----------\n",
    "print(\"Precomputing flattened lag features on full dataframe and merging...\")\n",
    "\n",
    "# Build a full flattened features DataFrame (same as X_all using build_flattened_features earlier)\n",
    "X_full = build_flattened_features(df_with_probs, last_t=LAST_T)   # uses df_with_probs which has indicators\n",
    "# X_full index are timestamps where features are valid\n",
    "\n",
    "# Now merge these flattened features into df_with_probs, aligning on index\n",
    "# For any timestamp without flattened features (start/end), the merge will produce NaNs  we can drop days with insufficient rows later\n",
    "df_merged = df_with_probs.merge(X_full, left_index=True, right_index=True, how='left', suffixes=('', '_lag'))\n",
    "\n",
    "# Optionally forward-fill or leave NaNs  we'll filter days later by required columns\n",
    "# Replace df_with_probs with df_merged for downstream slicing\n",
    "df_with_probs = df_merged\n",
    "print(\"Merged flattened features. New df columns count:\", len(df_with_probs.columns))\n",
    "\n",
    "# ---------- Build day-wise slices for RL env ----------\n",
    "def slice_days(df_all):\n",
    "    days = []\n",
    "    for date, daydf in df_all.groupby(df_all.index.date):\n",
    "        daydf = daydf.sort_index()\n",
    "        # require minimum length\n",
    "        if len(daydf) >= LAST_T + 10:\n",
    "            days.append(daydf)\n",
    "    return days\n",
    "\n",
    "all_days = slice_days(df_with_probs)\n",
    "# determine train/val/test day splits by date\n",
    "dates_all = np.array([d.index[0].date() for d in all_days])\n",
    "unique_dates = np.array(sorted(list({d.date() for d in df_with_probs.index})))\n",
    "# Simple split by date strings\n",
    "train_days = [d for d in all_days if d.index[0].date() <= pd.to_datetime(TRAIN_END_DATE).date()]\n",
    "val_days   = [d for d in all_days if (pd.to_datetime(TRAIN_END_DATE).date() < d.index[0].date() <= pd.to_datetime(VAL_END_DATE).date())]\n",
    "test_days  = [d for d in all_days if d.index[0].date() > pd.to_datetime(VAL_END_DATE).date()]\n",
    "\n",
    "print(\"Days: train\", len(train_days), \"val\", len(val_days), \"test\", len(test_days))\n",
    "\n",
    "# ---------- Define Gym Environment ----------\n",
    "class MinuteTradingEnv(gym.Env):\n",
    "    metadata = {'render.modes': ['human']}\n",
    "    def __init__(self, day_df, feature_cols, last_T=LAST_T, position_size=RL_POSITION_SIZE, round_trip_cost=RL_ROUND_TRIP_COST, include_probs=True):\n",
    "        super().__init__()\n",
    "        self.day_df = day_df.reset_index()\n",
    "        self.feature_cols = feature_cols\n",
    "        self.last_T = last_T\n",
    "        self.position_size = position_size\n",
    "        self.round_trip_cost = round_trip_cost\n",
    "        self.include_probs = include_probs\n",
    "\n",
    "        obs_dim = last_T * len(feature_cols) + (3 if include_probs else 0) + 1\n",
    "        self.observation_space = spaces.Box(low=-np.inf, high=np.inf, shape=(obs_dim,), dtype=np.float32)\n",
    "        self.action_space = spaces.Discrete(3)  # 0 flat, 1 long, 2 short\n",
    "\n",
    "        self.ptr = 0\n",
    "        self.equity = INITIAL_CAPITAL\n",
    "        self.current_position = 0\n",
    "        self.position_notional = 0.0\n",
    "        self.prices = self.day_df['close'].values\n",
    "        self.exec_prices = np.roll(self.prices, -1)\n",
    "        self.n = len(self.prices)\n",
    "\n",
    "    def reset(self):\n",
    "        self.ptr = self.last_T - 1\n",
    "        self.equity = INITIAL_CAPITAL\n",
    "        self.current_position = 0\n",
    "        self.position_notional = 0.0\n",
    "        return self._get_obs()\n",
    "\n",
    "    def step(self, action):\n",
    "        t = self.ptr\n",
    "        done = False\n",
    "        if t >= self.n - 2:\n",
    "            done = True\n",
    "            return self._get_obs(), 0.0, done, {'equity': self.equity, 'pnl': 0.0}\n",
    "\n",
    "        entry_price = float(self.exec_prices[t])\n",
    "        exit_price = float(self.exec_prices[t+1])\n",
    "        notional = self.position_size * self.equity\n",
    "        pnl = 0.0\n",
    "        if action == 0:\n",
    "            pnl = 0.0\n",
    "            self.current_position = 0\n",
    "            self.position_notional = 0.0\n",
    "        else:\n",
    "            sig = 1 if action == 1 else -1\n",
    "            units = notional / entry_price\n",
    "            raw_pnl = units * (exit_price - entry_price) * sig\n",
    "            tc = self.round_trip_cost * notional\n",
    "            pnl = raw_pnl - tc\n",
    "            self.current_position = sig\n",
    "            self.position_notional = notional\n",
    "\n",
    "        self.equity += pnl\n",
    "        # small trade penalty to discourage churn\n",
    "        trade_penalty = -0.0 * notional if action != 0 else 0.0\n",
    "        reward = pnl + trade_penalty\n",
    "\n",
    "        self.ptr += 1\n",
    "        if self.ptr >= self.n - 2:\n",
    "            done = True\n",
    "\n",
    "        info = {'equity': self.equity, 'pnl': pnl, 'position': self.current_position}\n",
    "        return self._get_obs(), reward, done, info\n",
    "\n",
    "    def _get_obs(self):\n",
    "        start = self.ptr - (self.last_T - 1)\n",
    "        window = self.day_df.iloc[start:self.ptr+1]\n",
    "        feats = window[self.feature_cols].values.flatten()\n",
    "        probs = window[['prob_dn','prob_neu','prob_up']].iloc[-1].values if self.include_probs else np.array([])\n",
    "        pos = np.array([float(self.current_position)], dtype=np.float32)\n",
    "        obs = np.concatenate([feats, probs, pos]).astype(np.float32)\n",
    "        return obs\n",
    "\n",
    "    def render(self, mode='human'):\n",
    "        print(f\"ptr={self.ptr}, equity={self.equity:.2f}, pos={self.current_position}\")\n",
    "\n",
    "# ---------- Prepare feature_cols for env observation ----------\n",
    "# Use the same num_cols from the flattened feature builder (take a subset that are raw time-series features)\n",
    "# For simplicity choose the lagged close, ret, vol features (3 * LAST_T) and append a few snapshot indicators\n",
    "lag_cols = []\n",
    "for lag in range(1, LAST_T+1):\n",
    "    lag_cols += [f'close_lag_{lag}', f'ret_lag_{lag}', f'vol_lag_{lag}']\n",
    "snapshot_cols = ['sma_5_now','ema_8_now','rsi_14_now','atr_14_now']\n",
    "feature_cols = lag_cols + snapshot_cols\n",
    "\n",
    "# ---------- Create a vectorized environment for training ----------\n",
    "def make_env_from_days(days_list):\n",
    "    def _init():\n",
    "        # pick a random day from days_list for each env instance\n",
    "        idx = np.random.randint(len(days_list))\n",
    "        daydf = days_list[idx]\n",
    "        return MinuteTradingEnv(daydf, feature_cols, last_T=LAST_T, position_size=RL_POSITION_SIZE, round_trip_cost=RL_ROUND_TRIP_COST)\n",
    "    return _init\n",
    "\n",
    "if len(train_days) == 0:\n",
    "    raise RuntimeError(\"No training days available. Check your dates and CSV.\")\n",
    "\n",
    "print(\"Creating vectorized training env...\")\n",
    "train_env = DummyVecEnv([make_env_from_days(train_days) for _ in range(4)])  # 4 parallel envs\n",
    "\n",
    "# ---------- Train PPO ----------\n",
    "print(\"Training PPO agent (this will take some time)...\")\n",
    "model_rl = PPO(\"MlpPolicy\", train_env, verbose=1, learning_rate=RL_LEARNING_RATE)\n",
    "model_rl.learn(total_timesteps=RL_TOTAL_TIMESTEPS)\n",
    "\n",
    "# Save RL model and scaler and classifier\n",
    "print(\"Saving artifacts...\")\n",
    "os.makedirs(\"artifacts\", exist_ok=True)\n",
    "joblib.dump(scaler, \"artifacts/scaler.joblib\")\n",
    "joblib.dump(clf, \"artifacts/lightgbm_clf.joblib\")\n",
    "model_rl.save(\"artifacts/ppo_trader\")\n",
    "\n",
    "# ---------- Evaluation on test days ----------\n",
    "def eval_on_days(model, days_list):\n",
    "    equity_curves = []\n",
    "    metrics_list = []\n",
    "    for daydf in days_list:\n",
    "        env = MinuteTradingEnv(daydf, feature_cols, last_T=LAST_T, position_size=RL_POSITION_SIZE, round_trip_cost=RL_ROUND_TRIP_COST)\n",
    "        obs = env.reset()\n",
    "        done = False\n",
    "        equities = []\n",
    "        while not done:\n",
    "            action, _states = model.predict(obs, deterministic=True)\n",
    "            obs, reward, done, info = env.step(int(action))\n",
    "            equities.append(info['equity'])\n",
    "        equities = pd.Series(equities, index=daydf.index[LAST_T:LAST_T+len(equities)])\n",
    "        equity_curves.append(equities)\n",
    "        # compute simple metrics\n",
    "        final_equity = equities.iloc[-1]\n",
    "        total_return = final_equity - INITIAL_CAPITAL\n",
    "        max_dd = ((equities.cummax() - equities) / equities.cummax()).max()\n",
    "        metrics_list.append({'date': daydf.index[0].date(), 'final_equity': final_equity, 'total_return': total_return, 'max_drawdown': max_dd})\n",
    "    return equity_curves, pd.DataFrame(metrics_list)\n",
    "\n",
    "print(\"Evaluating RL agent on test days...\")\n",
    "test_equities, test_metrics = eval_on_days(model_rl, test_days)\n",
    "print(test_metrics.describe())\n",
    "\n",
    "# Aggregate equity curve across test days by concatenation\n",
    "if test_equities:\n",
    "    combined = pd.concat(test_equities)\n",
    "    combined = combined.sort_index()\n",
    "    plt.figure(figsize=(10,5))\n",
    "    plt.plot(combined.values)\n",
    "    plt.title(\"RL agent combined equity across test days\")\n",
    "    plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fe4a71ab-8047-450e-9c27-561cc9177468",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "Computing indicators...\n",
      "Building flattened features (training X)...\n",
      "Sizes: (828995, 35) (92454, 35) (53249, 35)\n",
      "Training LightGBM classifier...\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.079133 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6375\n",
      "[LightGBM] [Info] Number of data points in the train set: 828995, number of used features: 25\n",
      "[LightGBM] [Info] Start training from score -1.093986\n",
      "[LightGBM] [Info] Start training from score -1.120401\n",
      "[LightGBM] [Info] Start training from score -1.081838\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[50]\tvalid_0's multi_logloss: 1.07027\n",
      "[100]\tvalid_0's multi_logloss: 1.06779\n",
      "[150]\tvalid_0's multi_logloss: 1.06773\n",
      "Early stopping, best iteration is:\n",
      "[121]\tvalid_0's multi_logloss: 1.06772\n",
      "Validation eval:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.38      0.21      0.27     30204\n",
      "           1       0.47      0.52      0.49     31811\n",
      "           2       0.37      0.50      0.42     30439\n",
      "\n",
      "    accuracy                           0.41     92454\n",
      "   macro avg       0.41      0.41      0.39     92454\n",
      "weighted avg       0.41      0.41      0.40     92454\n",
      "\n",
      "[[ 6238  9176 14790]\n",
      " [ 4031 16453 11327]\n",
      " [ 6077  9198 15164]]\n",
      "Merging classifier probabilities and precomputing features on full df...\n",
      "Merged df columns: 52\n",
      "Days: train 2212 val 248 test 142\n",
      "Sampling a training observation and a test observation for debugging...\n",
      "Train obs shape: (344,) first 8 values: [ 1.1290200e+04  1.8603662e-04  0.0000000e+00  1.1288100e+04\n",
      " -3.9863400e-05  0.0000000e+00  1.1288550e+04 -8.8584547e-06]\n",
      "Test obs shape: (344,) first 8 values: [2.3668801e+04 4.2267572e-04 0.0000000e+00 2.3658801e+04 2.1133831e-06\n",
      " 0.0000000e+00 2.3658750e+04 4.6496589e-05]\n",
      "Training PPO agent (this will take some time)...\n",
      "Using cpu device\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 364      |\n",
      "|    ep_rew_mean     | -15.4    |\n",
      "| time/              |          |\n",
      "|    fps             | 1052     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 7        |\n",
      "|    total_timesteps | 8192     |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 364         |\n",
      "|    ep_rew_mean          | -14.2       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 770         |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 21          |\n",
      "|    total_timesteps      | 16384       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011249918 |\n",
      "|    clip_fraction        | 0.127       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.09       |\n",
      "|    explained_variance   | -1.44       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0023     |\n",
      "|    n_updates            | 10          |\n",
      "|    policy_gradient_loss | -0.0114     |\n",
      "|    value_loss           | 0.112       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 364         |\n",
      "|    ep_rew_mean          | -13.3       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 713         |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 34          |\n",
      "|    total_timesteps      | 24576       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013972914 |\n",
      "|    clip_fraction        | 0.227       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.06       |\n",
      "|    explained_variance   | 0.115       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0488     |\n",
      "|    n_updates            | 20          |\n",
      "|    policy_gradient_loss | -0.0227     |\n",
      "|    value_loss           | 0.0408      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 364        |\n",
      "|    ep_rew_mean          | -12.5      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 676        |\n",
      "|    iterations           | 4          |\n",
      "|    time_elapsed         | 48         |\n",
      "|    total_timesteps      | 32768      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01419502 |\n",
      "|    clip_fraction        | 0.236      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1         |\n",
      "|    explained_variance   | 0.394      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0394    |\n",
      "|    n_updates            | 30         |\n",
      "|    policy_gradient_loss | -0.0234    |\n",
      "|    value_loss           | 0.0384     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 364         |\n",
      "|    ep_rew_mean          | -11.1       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 658         |\n",
      "|    iterations           | 5           |\n",
      "|    time_elapsed         | 62          |\n",
      "|    total_timesteps      | 40960       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016162189 |\n",
      "|    clip_fraction        | 0.244       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.921      |\n",
      "|    explained_variance   | 0.562       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.043      |\n",
      "|    n_updates            | 40          |\n",
      "|    policy_gradient_loss | -0.0289     |\n",
      "|    value_loss           | 0.04        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 364         |\n",
      "|    ep_rew_mean          | -9.83       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 661         |\n",
      "|    iterations           | 6           |\n",
      "|    time_elapsed         | 74          |\n",
      "|    total_timesteps      | 49152       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014730673 |\n",
      "|    clip_fraction        | 0.202       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.843      |\n",
      "|    explained_variance   | 0.722       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.00358    |\n",
      "|    n_updates            | 50          |\n",
      "|    policy_gradient_loss | -0.0245     |\n",
      "|    value_loss           | 0.0314      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 364        |\n",
      "|    ep_rew_mean          | -8.37      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 661        |\n",
      "|    iterations           | 7          |\n",
      "|    time_elapsed         | 86         |\n",
      "|    total_timesteps      | 57344      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01715805 |\n",
      "|    clip_fraction        | 0.193      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.745     |\n",
      "|    explained_variance   | 0.779      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0256    |\n",
      "|    n_updates            | 60         |\n",
      "|    policy_gradient_loss | -0.0246    |\n",
      "|    value_loss           | 0.0267     |\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "# train_rl_nifty_updated.py\n",
    "# Updated: fixes to ensure env observations match training, add VecNormalize, debug prints.\n",
    "\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from lightgbm import LGBMClassifier\n",
    "import joblib\n",
    "import ta\n",
    "\n",
    "# Stable Baselines3\n",
    "import gym\n",
    "from gym import spaces\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv, VecNormalize, VecMonitor\n",
    "\n",
    "# ----------------- CONFIG -----------------\n",
    "CSV_PATH = \"nifty_minute.csv\"     # path to your minute OHLCV CSV\n",
    "DATE_COL = \"date\"                 # ensure this matches your CSV\n",
    "HORIZON = 1       # minutes ahead to predict\n",
    "LAST_T = 10       # minutes of historical window\n",
    "TAU_PCT = 0.0001  # label threshold for Up/Down vs Neutral\n",
    "TRAIN_END_DATE = \"2023-12-31\"\n",
    "VAL_END_DATE   = \"2024-12-31\"\n",
    "INITIAL_CAPITAL = 100000.0\n",
    "\n",
    "# RL params\n",
    "RL_TOTAL_TIMESTEPS = 50000   # increase for real training\n",
    "RL_LEARNING_RATE = 3e-4\n",
    "RL_POSITION_SIZE = 0.1       # fraction of equity allocated per trade in env\n",
    "RL_ROUND_TRIP_COST = 0.0003  # transaction cost fraction\n",
    "# PPO exploration params\n",
    "PPO_ENT_COEF = 0.01\n",
    "PPO_VF_COEF = 0.5\n",
    "# ------------------------------------------\n",
    "\n",
    "# ---------- Utilities ----------\n",
    "def compute_technical_indicators(df):\n",
    "    df = df.copy()\n",
    "    df['close'] = pd.to_numeric(df['close'], errors='coerce')\n",
    "    df['open']  = pd.to_numeric(df['open'], errors='coerce')\n",
    "    df['high']  = pd.to_numeric(df['high'], errors='coerce')\n",
    "    df['low']   = pd.to_numeric(df['low'], errors='coerce')\n",
    "    df['volume'] = pd.to_numeric(df['volume'], errors='coerce').fillna(0)\n",
    "    df['return_1'] = df['close'].pct_change().fillna(0)\n",
    "    df['logret_1'] = np.log(df['close'] / df['close'].shift(1)).fillna(0)\n",
    "    df['sma_5'] = ta.trend.SMAIndicator(df['close'], window=5, fillna=True).sma_indicator()\n",
    "    df['sma_10'] = ta.trend.SMAIndicator(df['close'], window=10, fillna=True).sma_indicator()\n",
    "    df['ema_8'] = ta.trend.EMAIndicator(df['close'], window=8, fillna=True).ema_indicator()\n",
    "    df['rsi_14'] = ta.momentum.RSIIndicator(df['close'], window=14, fillna=True).rsi()\n",
    "    bb = ta.volatility.BollingerBands(df['close'], window=20, fillna=True)\n",
    "    df['bb_h'] = bb.bollinger_hband()\n",
    "    df['bb_l'] = bb.bollinger_lband()\n",
    "    df['atr_14'] = ta.volatility.average_true_range(df['high'], df['low'], df['close'], window=14, fillna=True)\n",
    "    return df\n",
    "\n",
    "def build_flattened_features(df, last_t=LAST_T):\n",
    "    rows = []\n",
    "    idxs = []\n",
    "    for i in range(last_t, len(df) - HORIZON):\n",
    "        window = df.iloc[i-last_t:i]\n",
    "        cur = df.iloc[i]\n",
    "        feat = {}\n",
    "        for j in range(last_t):\n",
    "            row = window.iloc[j]\n",
    "            lag = last_t - j\n",
    "            feat[f'close_lag_{lag}'] = row['close']\n",
    "            feat[f'ret_lag_{lag}'] = row['return_1']\n",
    "            feat[f'vol_lag_{lag}'] = row['volume']\n",
    "        feat['close_now'] = cur['close']\n",
    "        feat['sma_5_now'] = cur['sma_5']\n",
    "        feat['ema_8_now'] = cur['ema_8']\n",
    "        feat['rsi_14_now'] = cur['rsi_14']\n",
    "        feat['atr_14_now'] = cur['atr_14']\n",
    "        rows.append(feat)\n",
    "        idxs.append(df.index[i])\n",
    "    X = pd.DataFrame(rows, index=idxs)\n",
    "    return X\n",
    "\n",
    "def build_labels(df, X_index, horizon=HORIZON, tau=TAU_PCT):\n",
    "    future = df['close'].shift(-horizon).reindex(X_index)\n",
    "    current = df['close'].reindex(X_index)\n",
    "    ret = (future.values - current.values) / current.values\n",
    "    labels = np.where(ret > tau, 2, np.where(ret < -tau, 0, 1))\n",
    "    return pd.Series(labels, index=X_index)\n",
    "\n",
    "# ---------- Load & preprocess ----------\n",
    "print(\"Loading data...\")\n",
    "df = pd.read_csv(CSV_PATH)\n",
    "df[DATE_COL] = pd.to_datetime(df[DATE_COL])\n",
    "df = df.sort_values(DATE_COL).set_index(DATE_COL)\n",
    "try:\n",
    "    df = df.between_time(\"09:15\", \"15:30\")\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "print(\"Computing indicators...\")\n",
    "df = compute_technical_indicators(df)\n",
    "\n",
    "print(\"Building flattened features (training X)...\")\n",
    "X = build_flattened_features(df, last_t=LAST_T)\n",
    "y = build_labels(df, X.index, horizon=HORIZON, tau=TAU_PCT)\n",
    "mask = ~(X.isna().any(axis=1) | pd.isna(y))\n",
    "X = X.loc[mask]\n",
    "y = y.loc[mask]\n",
    "\n",
    "dates = X.index.normalize()\n",
    "train_mask = dates <= pd.to_datetime(TRAIN_END_DATE)\n",
    "val_mask   = (dates > pd.to_datetime(TRAIN_END_DATE)) & (dates <= pd.to_datetime(VAL_END_DATE))\n",
    "test_mask  = dates > pd.to_datetime(VAL_END_DATE)\n",
    "\n",
    "X_train, y_train = X.loc[train_mask], y.loc[train_mask]\n",
    "X_val, y_val     = X.loc[val_mask], y.loc[val_mask]\n",
    "X_test, y_test   = X.loc[test_mask], y.loc[test_mask]\n",
    "\n",
    "print(\"Sizes:\", X_train.shape, X_val.shape, X_test.shape)\n",
    "\n",
    "# Scale features\n",
    "num_cols = X_train.columns.tolist()\n",
    "scaler = StandardScaler()\n",
    "X_train_s = pd.DataFrame(scaler.fit_transform(X_train[num_cols]), columns=num_cols, index=X_train.index)\n",
    "X_val_s   = pd.DataFrame(scaler.transform(X_val[num_cols]), columns=num_cols, index=X_val.index)\n",
    "X_test_s  = pd.DataFrame(scaler.transform(X_test[num_cols]), columns=num_cols, index=X_test.index)\n",
    "\n",
    "# ---------- Train LightGBM ----------\n",
    "print(\"Training LightGBM classifier...\")\n",
    "clf = LGBMClassifier(objective='multiclass', num_class=3, learning_rate=0.05, n_estimators=1000, num_leaves=31, random_state=42)\n",
    "from lightgbm import early_stopping, log_evaluation\n",
    "clf.fit(X_train_s, y_train, eval_set=[(X_val_s, y_val)], eval_metric='multi_logloss',\n",
    "        callbacks=[early_stopping(stopping_rounds=50), log_evaluation(period=50)])\n",
    "\n",
    "print(\"Validation eval:\")\n",
    "preds_val = clf.predict(X_val_s)\n",
    "print(classification_report(y_val, preds_val))\n",
    "print(confusion_matrix(y_val, preds_val))\n",
    "\n",
    "# ---------- Merge classifier probs into df and precompute flattened features ----------\n",
    "print(\"Merging classifier probabilities and precomputing features on full df...\")\n",
    "# Predict on entire X (train+val+test) and build prob df aligned to X indices\n",
    "X_all = pd.concat([X_train, X_val, X_test])\n",
    "X_all_s = pd.DataFrame(scaler.transform(X_all[num_cols]), columns=num_cols, index=X_all.index)\n",
    "probs_all = clf.predict_proba(X_all_s)\n",
    "prob_df = pd.DataFrame(probs_all, index=X_all.index, columns=['prob_dn','prob_neu','prob_up'])\n",
    "\n",
    "# Merge probs into base df and forward-fill, then build flattened features from df_with_probs\n",
    "df_with_probs = df.merge(prob_df, left_index=True, right_index=True, how='left')\n",
    "df_with_probs[['prob_dn','prob_neu','prob_up']] = df_with_probs[['prob_dn','prob_neu','prob_up']].fillna(method='ffill').fillna(1/3)\n",
    "\n",
    "# Precompute flattened features for the full df_with_probs and merge (ensures day slices include lag cols)\n",
    "X_full = build_flattened_features(df_with_probs, last_t=LAST_T)\n",
    "df_merged = df_with_probs.merge(X_full, left_index=True, right_index=True, how='left')\n",
    "# drop rows without lag features (start/end)\n",
    "df_merged = df_merged.dropna(subset=[f'close_lag_1'])  # ensure lag cols present\n",
    "df_with_probs = df_merged.copy()\n",
    "print(\"Merged df columns:\", len(df_with_probs.columns))\n",
    "\n",
    "# ---------- Build day-wise slices ----------\n",
    "def slice_days(df_all):\n",
    "    days = []\n",
    "    for date, daydf in df_all.groupby(df_all.index.date):\n",
    "        daydf = daydf.sort_index()\n",
    "        # ensure required feature columns exist\n",
    "        required = [f'close_lag_{i}' for i in range(1, LAST_T+1)] + ['prob_dn','prob_neu','prob_up'] + ['sma_5_now','ema_8_now','rsi_14_now','atr_14_now']\n",
    "        if set(required).issubset(set(daydf.columns)) and len(daydf) >= LAST_T + 10:\n",
    "            days.append(daydf)\n",
    "    return days\n",
    "\n",
    "all_days = slice_days(df_with_probs)\n",
    "train_days = [d for d in all_days if d.index[0].date() <= pd.to_datetime(TRAIN_END_DATE).date()]\n",
    "val_days   = [d for d in all_days if (pd.to_datetime(TRAIN_END_DATE).date() < d.index[0].date() <= pd.to_datetime(VAL_END_DATE).date())]\n",
    "test_days  = [d for d in all_days if d.index[0].date() > pd.to_datetime(VAL_END_DATE).date()]\n",
    "\n",
    "print(\"Days: train\", len(train_days), \"val\", len(val_days), \"test\", len(test_days))\n",
    "if len(train_days) == 0:\n",
    "    raise RuntimeError(\"No training days available. Check your dates and CSV.\")\n",
    "\n",
    "# ---------- Define Gym Env ----------\n",
    "class MinuteTradingEnv(gym.Env):\n",
    "    metadata = {'render.modes': ['human']}\n",
    "    def __init__(self, day_df, feature_cols, last_T=LAST_T, position_size=RL_POSITION_SIZE, round_trip_cost=RL_ROUND_TRIP_COST, include_probs=True):\n",
    "        super().__init__()\n",
    "        self.day_df = day_df.reset_index()\n",
    "        self.feature_cols = feature_cols\n",
    "        self.last_T = last_T\n",
    "        self.position_size = position_size\n",
    "        self.round_trip_cost = round_trip_cost\n",
    "        self.include_probs = include_probs\n",
    "\n",
    "        obs_dim = last_T * len(feature_cols) + (3 if include_probs else 0) + 1\n",
    "        self.observation_space = spaces.Box(low=-np.inf, high=np.inf, shape=(obs_dim,), dtype=np.float32)\n",
    "        self.action_space = spaces.Discrete(3)\n",
    "\n",
    "        self.ptr = 0\n",
    "        self.equity = INITIAL_CAPITAL\n",
    "        self.current_position = 0\n",
    "        self.position_notional = 0.0\n",
    "        self.prices = self.day_df['close'].values\n",
    "        self.exec_prices = np.roll(self.prices, -1)\n",
    "        self.n = len(self.prices)\n",
    "\n",
    "    def reset(self):\n",
    "        self.ptr = self.last_T - 1\n",
    "        self.equity = INITIAL_CAPITAL\n",
    "        self.current_position = 0\n",
    "        self.position_notional = 0.0\n",
    "        return self._get_obs()\n",
    "\n",
    "    def step(self, action):\n",
    "        t = self.ptr\n",
    "        done = False\n",
    "        if t >= self.n - 2:\n",
    "            done = True\n",
    "            return self._get_obs(), 0.0, done, {'equity': self.equity, 'pnl': 0.0}\n",
    "\n",
    "        entry_price = float(self.exec_prices[t])\n",
    "        exit_price = float(self.exec_prices[t+1])\n",
    "        notional = self.position_size * self.equity\n",
    "        pnl = 0.0\n",
    "        if action == 0:\n",
    "            pnl = 0.0\n",
    "            self.current_position = 0\n",
    "            self.position_notional = 0.0\n",
    "        else:\n",
    "            sig = 1 if action == 1 else -1\n",
    "            units = notional / entry_price\n",
    "            raw_pnl = units * (exit_price - entry_price) * sig\n",
    "            tc = self.round_trip_cost * notional\n",
    "            pnl = raw_pnl - tc\n",
    "            self.current_position = sig\n",
    "            self.position_notional = notional\n",
    "\n",
    "        self.equity += pnl\n",
    "        reward = pnl\n",
    "        self.ptr += 1\n",
    "        if self.ptr >= self.n - 2:\n",
    "            done = True\n",
    "        info = {'equity': self.equity, 'pnl': pnl, 'position': self.current_position}\n",
    "        return self._get_obs(), reward, done, info\n",
    "\n",
    "    def _get_obs(self):\n",
    "        start = self.ptr - (self.last_T - 1)\n",
    "        window = self.day_df.iloc[start:self.ptr+1]\n",
    "        feats = window[self.feature_cols].values.flatten()\n",
    "        probs = window[['prob_dn','prob_neu','prob_up']].iloc[-1].values if self.include_probs else np.array([])\n",
    "        pos = np.array([float(self.current_position)], dtype=np.float32)\n",
    "        obs = np.concatenate([feats, probs, pos]).astype(np.float32)\n",
    "        return obs\n",
    "\n",
    "    def render(self, mode='human'):\n",
    "        print(f\"ptr={self.ptr}, equity={self.equity:.2f}, pos={self.current_position}\")\n",
    "\n",
    "# ---------- Prepare feature_cols ----------\n",
    "lag_cols = []\n",
    "for lag in range(1, LAST_T+1):\n",
    "    lag_cols += [f'close_lag_{lag}', f'ret_lag_{lag}', f'vol_lag_{lag}']\n",
    "snapshot_cols = ['sma_5_now','ema_8_now','rsi_14_now','atr_14_now']\n",
    "feature_cols = lag_cols + snapshot_cols\n",
    "\n",
    "# ---------- Create vectorized env with normalization and monitor ----------\n",
    "def make_env_from_days(days_list):\n",
    "    def _init():\n",
    "        idx = np.random.randint(len(days_list))\n",
    "        daydf = days_list[idx]\n",
    "        return MinuteTradingEnv(daydf, feature_cols, last_T=LAST_T, position_size=RL_POSITION_SIZE, round_trip_cost=RL_ROUND_TRIP_COST)\n",
    "    return _init\n",
    "\n",
    "n_envs = min(4, max(1, len(train_days)//10))\n",
    "vec_fns = [make_env_from_days(train_days) for _ in range(n_envs)]\n",
    "train_env = DummyVecEnv(vec_fns)\n",
    "train_env = VecNormalize(train_env, norm_obs=True, norm_reward=True, clip_obs=10.)\n",
    "train_env = VecMonitor(train_env)  # records episode rewards\n",
    "\n",
    "# ---------- Debug: sample obs from train env and a test env ----------\n",
    "print(\"Sampling a training observation and a test observation for debugging...\")\n",
    "sample_env = make_env_from_days(train_days)()\n",
    "obs_sample = sample_env.reset()\n",
    "print(\"Train obs shape:\", obs_sample.shape, \"first 8 values:\", obs_sample.flatten()[:8])\n",
    "\n",
    "test_env0 = MinuteTradingEnv(test_days[0], feature_cols) if len(test_days)>0 else sample_env\n",
    "obs_test = test_env0.reset()\n",
    "print(\"Test obs shape:\", obs_test.shape, \"first 8 values:\", obs_test.flatten()[:8])\n",
    "\n",
    "# ---------- Train PPO ----------\n",
    "print(\"Training PPO agent (this will take some time)...\")\n",
    "model_rl = PPO(\"MlpPolicy\", train_env, verbose=1, learning_rate=RL_LEARNING_RATE, ent_coef=PPO_ENT_COEF, vf_coef=PPO_VF_COEF)\n",
    "model_rl.learn(total_timesteps=RL_TOTAL_TIMESTEPS)\n",
    "\n",
    "# Save artifacts\n",
    "os.makedirs(\"artifacts\", exist_ok=True)\n",
    "joblib.dump(scaler, \"artifacts/scaler.joblib\")\n",
    "joblib.dump(clf, \"artifacts/lightgbm_clf.joblib\")\n",
    "model_rl.save(\"artifacts/ppo_trader\")\n",
    "\n",
    "# ---------- Evaluation with action debug ----------\n",
    "def eval_on_days(model, days_list):\n",
    "    equity_curves = []\n",
    "    metrics_list = []\n",
    "    for daydf in days_list:\n",
    "        # skip days missing required cols\n",
    "        required = set(feature_cols + ['prob_dn','prob_neu','prob_up'])\n",
    "        if not required.issubset(set(daydf.columns)):\n",
    "            continue\n",
    "        env = MinuteTradingEnv(daydf, feature_cols, last_T=LAST_T, position_size=RL_POSITION_SIZE, round_trip_cost=RL_ROUND_TRIP_COST)\n",
    "        obs = env.reset()\n",
    "        done = False\n",
    "        equities = []\n",
    "        actions = []\n",
    "        while not done:\n",
    "            action, _states = model.predict(obs, deterministic=True)\n",
    "            actions.append"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de61e63d-d81f-40a2-9410-143c7ec1f5a9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
